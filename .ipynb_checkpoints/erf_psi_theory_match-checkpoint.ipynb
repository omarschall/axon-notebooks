{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d61ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "import torch\n",
    "sys.path.append('/home/om2382/mft-theory/')\n",
    "from cluster import *\n",
    "from core import *\n",
    "from empirics import *\n",
    "from functions import *\n",
    "from ode_methods import *\n",
    "from plotting import *\n",
    "from theory import *\n",
    "from utils import *\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae61a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To do\n",
    "#memory issue to get more data points and larger networks in estimating psi\n",
    "#turn psi estimation into function suite for different cases\n",
    "#find relevant range of connectivity parameter values to simluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3bf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SET UP ALL CONFIGS --- ###\n",
    "from itertools import product\n",
    "n_seeds = 5\n",
    "macro_configs = config_generator(g=[3, 5.5, 8, 10, 15, 20])\n",
    "\n",
    "micro_configs = tuple(product(macro_configs, list(range(n_seeds))))\n",
    "prototype = False\n",
    "\n",
    "### --- SELECT PARTICULAR CONFIG --- ###\n",
    "try:\n",
    "    i_job = int(os.environ['SLURM_ARRAY_TASK_ID']) - 1\n",
    "except KeyError:\n",
    "    i_job = 0\n",
    "    prototype = True\n",
    "params, i_seed = micro_configs[i_job]\n",
    "i_config = i_job//n_seeds\n",
    "\n",
    "new_random_seed_per_condition = True\n",
    "if new_random_seed_per_condition:\n",
    "    np.random.seed(i_job)\n",
    "else: #Match random seeds across conditions\n",
    "    np.random.seed(i_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d81841",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Set parameters --- ###\n",
    "N = 2000\n",
    "g = params['g']\n",
    "T_window = 100\n",
    "dT = 0.05\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "lags = np.arange(0, T_window, dT)\n",
    "n_lags = int(T_window/dT)\n",
    "lags_full = np.concatenate([-lags[-n_lags:][::-1], lags[1:n_lags], np.array([lags[-1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8d5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Estimate psi empirically --- ###\n",
    "\n",
    "dT_emp = 0.5\n",
    "lags_emp = np.arange(0, T_window, dT_emp)\n",
    "n_lags_emp = int(T_window/dT_emp)\n",
    "\n",
    "#compute psi\n",
    "W = g*np.random.normal(0, 1/np.sqrt(N), (N, N))\n",
    "W_ = torch.from_numpy(W).type(torch.FloatTensor).to(0)\n",
    "Psi = estimate_psi(lags_emp, T_sim=5000, dt_save=dT_emp, dt=0.1,\n",
    "                   W=W_, phi_torch=phi_torch, T_save_delay=100, N_batch=1, N_loops=10)\n",
    "\n",
    "#symmetrize psi for comparison\n",
    "Psi = Psi.cpu().detach().numpy()\n",
    "Psi_emp = np.concatenate([Psi[-n_lags_emp:][::-1], Psi[1:n_lags_emp]])\n",
    "lags_emp_full = np.concatenate([-lags_emp[-n_lags_emp:][::-1], lags_emp[1:n_lags_emp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Optional: measure single-unit properties empirically --- ###\n",
    "if False:\n",
    "    phi_prime = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "    generate_W = lambda g, N: g*np.random.normal(0, 1/np.sqrt(N), (N, N))\n",
    "    \n",
    "    C_Phi_half_emp, alpha_emp = estimate_single_unit_autocov_and_alpha(lags, T_sim=3000, dt_save=dT, dt=0.05,\n",
    "                                                                       generate_W=partial(generate_W, g=g, N=N),\n",
    "                                                                       N=N, phi_torch=phi_torch, phi_prime=phi_prime_torch,\n",
    "                                                                       T_save_delay=100,\n",
    "                                                                       N_batch=2, N_disorder=2)\n",
    "if False:\n",
    "    alpha = alpha_emp\n",
    "    C_Phi_half = C_Phi_half_emp.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Compute single-unit properties\n",
    "\n",
    "d = compute_Delta_0(g=g)\n",
    "time, Delta_T = integrate_potential(d, g=g, tau_max=T_window, N_tau=int(T_window/dT))\n",
    "Delta_T = fix(Delta_T)\n",
    "C_Phi_half = compute_C_simple(d, Delta_T)\n",
    "alpha = compute_phi_prime_avg(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13575b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Compute Psi from theory --- ###\n",
    "\n",
    "#Define relevant single-unit functions\n",
    "C_phi = np.concatenate([C_Phi_half[-n_lags:][::-1],\n",
    "                        C_Phi_half[1:n_lags],\n",
    "                        np.array([C_Phi_half[-1]])])\n",
    "C_phi_omega = fft(C_phi, dT)\n",
    "T = len(C_phi)\n",
    "t_indices= np.concatenate([np.arange(0, T//2), np.arange(-T//2, 0)])\n",
    "sampfreq = 1/dT\n",
    "w = 2*np.pi*sampfreq*t_indices/T\n",
    "C_phi_C_phi = np.multiply.outer(C_phi_omega, C_phi_omega)\n",
    "S_phi = alpha/(np.sqrt(2*np.pi)*(1 + 1j*w))\n",
    "S_phi_S_phi = np.multiply.outer(S_phi, S_phi)\n",
    "\n",
    "#Compute psi for iid random network\n",
    "Psi_PRX = (1/(np.abs(1 - 2*np.pi*(g**2) * (S_phi_S_phi))**2) - 1)*C_phi_C_phi\n",
    "Psi_PRX_tau = ifft(Psi_PRX, dT)\n",
    "Psi_tau_tau = np.diag(Psi_PRX_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Double check with David's code --- ###\n",
    "Psi_tau_2 = compute_psi_theory(symmetrize(Delta_T), g, dT)\n",
    "Ptt2 = np.diag(Psi_tau_2)\n",
    "Psi_tau_tau_2 = np.concatenate([Ptt2[-len(Ptt2)//2:], Ptt2[:len(Ptt2)//2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a651b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_data = np.array([Psi_emp, Psi_tau_tau, Psi_tau_tau_2])\n",
    "processed_data = np.array([lags_emp_full, Psi_emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(lags_emp_full, Psi_emp)\n",
    "#plt.plot(lags_full, Psi_tau_tau)\n",
    "#plt.plot(lags_full, Psi_tau_tau_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SAVE RESULTS -- ###\n",
    "result = {'sim': None, 'i_seed': i_seed, 'config': params,\n",
    "          'i_config': i_config, 'i_job': i_job}\n",
    "try:\n",
    "    result['processed_data'] = processed_data\n",
    "except NameError:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    save_dir = os.environ['SAVEDIR']\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_path = os.path.join(save_dir, 'result_{}'.format(i_job))\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60885180",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Truncate file above\n",
    "file_name = 'erf_psi_theory_match'\n",
    "job_name = 'PRX_match_attempt_2'\n",
    "project_dir = '/home/om2382/low-rank-dims/'\n",
    "main_script_path = os.path.join(project_dir, 'cluster_main_scripts', job_name + '.py')\n",
    "get_ipython().run_cell_magic('javascript', '', 'IPython.notebook.save_notebook()')\n",
    "get_ipython().system('jupyter nbconvert --to script --no-prompt {}.ipynb'.format(file_name))\n",
    "get_ipython().system('awk \"/###Truncate/ {{exit}} {{print}}\" {}.py'.format(file_name))\n",
    "get_ipython().system('sed -i \"/###Truncate/Q\" {}.py'.format(file_name))\n",
    "get_ipython().system('mv {}.py {}'.format(file_name, main_script_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99850352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Submit job to cluster\n",
    "n_jobs = len(micro_configs)\n",
    "write_job_file(job_name, py_file_name='{}.py'.format(job_name), mem=64, n_hours=1, n_gpus=1)\n",
    "job_script_path = os.path.join(project_dir, 'job_scripts', job_name + '.s')\n",
    "submit_job(job_script_path, n_jobs, execute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c350a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Get job status\n",
    "get_ipython().system('squeue -u om2382')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/om2382/low-rank-dims/'\n",
    "job_name = 'PRX_match_attempt_2'\n",
    "job_script_path = os.path.join(project_dir, 'job_scripts', job_name + '.s')\n",
    "configs_array, results_array, key_order, sim_dict = unpack_processed_data(job_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918617b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -t ../job_scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab66061",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e37627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 1, figsize=(4, 12))\n",
    "T_window = 100\n",
    "dT = 0.05\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "lags = np.arange(0, T_window, dT)\n",
    "n_lags = int(T_window/dT)\n",
    "lags_full = np.concatenate([-lags[-n_lags:][::-1], lags[1:n_lags], np.array([lags[-1]])])\n",
    "for i in range(6):\n",
    "    \n",
    "    #Choose g\n",
    "    g = configs_array['g'][i]\n",
    "    \n",
    "    ### --- Compute single-unit properties\n",
    "    d = compute_Delta_0(g=g)\n",
    "    time, Delta_T = integrate_potential(d, g=g, tau_max=T_window, N_tau=int(T_window/dT))\n",
    "    Delta_T = fix(Delta_T)\n",
    "    C_Phi_half = compute_C_simple(d, Delta_T)\n",
    "    alpha = compute_phi_prime_avg(d)\n",
    "    \n",
    "    ### --- Compute Psi from theory --- ###\n",
    "\n",
    "    #Define relevant single-unit functions\n",
    "    C_phi = np.concatenate([C_Phi_half[-n_lags:][::-1],\n",
    "                            C_Phi_half[1:n_lags],\n",
    "                            np.array([C_Phi_half[-1]])])\n",
    "    C_phi_omega = fft(C_phi, dT)\n",
    "    T = len(C_phi)\n",
    "    t_indices= np.concatenate([np.arange(0, T//2), np.arange(-T//2, 0)])\n",
    "    sampfreq = 1/dT\n",
    "    w = 2*np.pi*sampfreq*t_indices/T\n",
    "    C_phi_C_phi = np.multiply.outer(C_phi_omega, C_phi_omega)\n",
    "    S_phi = alpha/(np.sqrt(2*np.pi)*(1 + 1j*w))\n",
    "    S_phi_S_phi = np.multiply.outer(S_phi, S_phi)\n",
    "\n",
    "    #Compute psi for iid random network\n",
    "    Psi_PRX = (1/(np.abs(1 - 2*np.pi*(g**2) * (S_phi_S_phi))**2) - 1)*C_phi_C_phi\n",
    "    Psi_PRX_tau = ifft(Psi_PRX, dT)\n",
    "    Psi_tau_tau = np.diag(Psi_PRX_tau)\n",
    "    \n",
    "    ### --- Double check with David's code --- ###\n",
    "    Psi_tau_2 = compute_psi_theory(symmetrize(Delta_T), g, dT)\n",
    "    Ptt2 = np.diag(Psi_tau_2)\n",
    "    Psi_tau_tau_2 = np.concatenate([Ptt2[-len(Ptt2)//2:], Ptt2[:len(Ptt2)//2]])\n",
    "\n",
    "    for j in range(5):\n",
    "        ax[i].plot(results_array[i,j,0,:],\n",
    "                   results_array[i,j,1,:], color='C0', alpha=0.1)\n",
    "    \n",
    "    ax[i].plot(results_array[i,j,0,:],\n",
    "               results_array[i,:,1,:].mean(0), color='C0', alpha=1)\n",
    "    ax[i].plot(lags_full, Psi_tau_tau, color='C1')\n",
    "    ax[i].plot(lags_full, Psi_tau_tau_2, color='C2')\n",
    "    ax[i].set_ylim([0, 14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-test-3",
   "language": "python",
   "name": "torch-test-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
