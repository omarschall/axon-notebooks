{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d61ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "import torch\n",
    "sys.path.append('/home/om2382/mft-theory/')\n",
    "from cluster import *\n",
    "from core import *\n",
    "from empirics import *\n",
    "from functions import *\n",
    "from LDR_dim import *\n",
    "from ode_methods import *\n",
    "from plotting import *\n",
    "from theory import *\n",
    "from utils import *\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SET UP ALL CONFIGS --- ###\n",
    "from itertools import product\n",
    "n_seeds = 10\n",
    "macro_configs = config_generator(D0=[3, 4.15, 5.3])\n",
    "micro_configs = tuple(product(macro_configs, list(range(n_seeds))))\n",
    "prototype = False\n",
    "\n",
    "### --- SELECT PARTICULAR CONFIG --- ###\n",
    "try:\n",
    "    i_job = int(os.environ['SLURM_ARRAY_TASK_ID']) - 1\n",
    "except KeyError:\n",
    "    i_job = 0\n",
    "    prototype = True\n",
    "params, i_seed = micro_configs[i_job]\n",
    "i_config = i_job//n_seeds\n",
    "\n",
    "new_random_seed_per_condition = True\n",
    "if new_random_seed_per_condition:\n",
    "    np.random.seed(i_job)\n",
    "else: #Match random seeds across conditions\n",
    "    np.random.seed(i_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d314c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "N_bins = 4000\n",
    "gamma = 0.99\n",
    "D_bulk = 2\n",
    "omega_star = 0.25\n",
    "alpha = 1\n",
    "R = 2\n",
    "gamma = 0.99\n",
    "i_min = np.argmin(np.abs(2*np.pi*np.fft.fftfreq(N_bins, T/N_bins) - omega_star))\n",
    "omega_star = 2*np.pi*np.fft.fftfreq(N_bins, T/N_bins)[i_min]\n",
    "cos_theta = 1.0 / np.sqrt(1.0 + omega_star**2)\n",
    "res_spont = solve_spontaneous(N=N_bins, T=T,\n",
    "                              alpha=alpha, R=R, D_bulk=D_bulk, gamma=gamma,\n",
    "                              g=None,                      # if provided, g_eff := g; else g_eff := sqrt(alpha*R)*D\n",
    "                              max_iters=500, tol=1e-9, mix=0.5)\n",
    "\n",
    "D_crit_1 = 1/(gamma * cos_theta * res_spont['gain'])\n",
    "\n",
    "### CHANGE THIS VALUE TO CHANGE REGIME FOR THEORY AND SIMULATION ###\n",
    "D0 = params['D0']\n",
    "D0 = 4.15 #chaotic task-selected\n",
    "#D0 = 5.3 #nonchaotic task-selected\n",
    "\n",
    "\n",
    "#Solve for theoretical autocovariance functions\n",
    "\n",
    "res = solve_condensed(\n",
    "    N=N_bins, T=T,\n",
    "    alpha=alpha, R=2,\n",
    "    D_bulk=D_bulk,   # ensure D_bulk < D0*cosÎ¸*\n",
    "    D0=D0,\n",
    "    gamma=gamma, omega_star=omega_star,\n",
    "    g=None, mix=0.5, iters=3000, tol=1e-9, plus=True\n",
    ")\n",
    "Cphi = Cphi_from_Cx_time(res['Cx_tau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe28d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Set empirical parameters --- ###\n",
    "\n",
    "#network properties size\n",
    "N = 5000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "#Set tasks\n",
    "R = 2\n",
    "gamma = 0.99\n",
    "alpha = alpha\n",
    "D_ = 2\n",
    "N_tasks = int(alpha * N)\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "#g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * D_\n",
    "g = np.sqrt(alpha * R * np.mean(D**2))\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance_block_haar(R=R,\n",
    "                                                                                            gamma=gamma,\n",
    "                                                                                            report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "\n",
    "freq = omega_star\n",
    "theta0 = np.arctan(freq)\n",
    "#D0 = params['D0']\n",
    "Cs = np.transpose(sigma_mn_all, axes=(2,0,1))\n",
    "real_freq = gamma * np.cos(theta0)\n",
    "i_mode = np.argmin(np.abs(np.amax(np.linalg.eigvals(Cs).real, 1) - real_freq))\n",
    "D_changed = D.copy()\n",
    "D_changed[i_mode] = D0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Observe some activity\n",
    "dt = 0.05\n",
    "\n",
    "#sample W\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D_changed, N)\n",
    "\n",
    "### --- Estimate C empirically --- ###\n",
    "\n",
    "x, r = sample_activity(T_sim=200, dt_save=0.05, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=True, T_save_delay=0, noise_series=None)\n",
    "Z = np.einsum('air, ti -> atr', all_loadings[i_mode:i_mode+1, :, 2:4], r) * D_changed[i_mode:i_mode+1,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Example neuron currents')\n",
    "plt.plot(x[:,0], 'C0')\n",
    "plt.plot(x[:,1], 'C0')\n",
    "plt.figure()\n",
    "plt.title('Active Task Latent Variables')\n",
    "plt.plot(Z[0,:,0], '#69469C')\n",
    "plt.plot(Z[0,:,1], '#AB85BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate autocovariance statistics\n",
    "\n",
    "#lags window\n",
    "dt = 0.05\n",
    "T_window_emp = 80\n",
    "dT_emp = 0.5\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "C_x_emp_avg = 0\n",
    "C_phi_emp_avg = 0\n",
    "N_W_samples = 1\n",
    "for i_W_sample in range(N_W_samples):\n",
    "    \n",
    "    #fix sample\n",
    "    W_, all_loadings = sample_W_optimized(sigma_mn_all, D_changed, N)\n",
    "    \n",
    "    ### --- Estimate C empirically --- ###\n",
    "\n",
    "    x, r = sample_activity(T_sim=3000, dt_save=dT_emp, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                           runga_kutta=True, T_save_delay=100, noise_series=None)\n",
    "    x = torch.from_numpy(x).type(torch.FloatTensor).to(0)\n",
    "    r = torch.from_numpy(r).type(torch.FloatTensor).to(0)\n",
    "    C_x_emp = compute_lagged_xcov(x[:,None,:], x[:,None,:], lags_emp, dt_save=dT_emp)\n",
    "    C_phi_emp = compute_lagged_xcov(r[:,None,:], r[:,None,:], lags_emp, dt_save=dT_emp)\n",
    "    C_x_emp_avg += C_x_emp / N_W_samples\n",
    "    C_phi_emp_avg += C_phi_emp / N_W_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c30d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cx_tau_emp = C_x_emp_avg.cpu().numpy().squeeze().mean(-1)\n",
    "Cphi_tau_emp = C_phi_emp_avg.cpu().numpy().squeeze().mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea969c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For better fits, increase N, N_W_samples, and T_sim= argument ###\n",
    "\n",
    "time_vec_theory = np.arange(0, 60, dt)\n",
    "time_vec_emp = np.arange(0, 60, dT_emp)\n",
    "plt.title('Current autocovariance')\n",
    "plt.plot(time_vec_theory, res['Cx_tau'][:len(time_vec_theory)], 'k',linestyle='--')\n",
    "plt.plot(time_vec_emp, Cx_tau_emp[:len(time_vec_emp)], 'C0')\n",
    "plt.figure()\n",
    "plt.title('Firing rate autocovariance')\n",
    "plt.plot(time_vec_theory, Cphi[:len(time_vec_theory)], 'k', linestyle='--')\n",
    "plt.plot(time_vec_emp, Cphi_tau_emp[:len(time_vec_emp)], '#E69629')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-test-3",
   "language": "python",
   "name": "torch-test-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
