{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d61ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "import torch\n",
    "sys.path.append('/home/om2382/mft-theory/')\n",
    "from cluster import *\n",
    "from core import *\n",
    "from empirics import *\n",
    "from functions import *\n",
    "from LDR_dim import *\n",
    "from ode_methods import *\n",
    "from plotting import *\n",
    "from theory import *\n",
    "from utils import *\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3bf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SET UP ALL CONFIGS --- ###\n",
    "from itertools import product\n",
    "n_seeds = 10\n",
    "#low_freqs = list(np.round(np.arange(0.2, 0.25, 0.01), 2))\n",
    "#high_freqs = list(np.round(np.arange(0.25, 5, 0.05), 2))\n",
    "macro_configs = config_generator()\n",
    "\n",
    "micro_configs = tuple(product(macro_configs, list(range(n_seeds))))\n",
    "prototype = False\n",
    "\n",
    "### --- SELECT PARTICULAR CONFIG --- ###\n",
    "try:\n",
    "    i_job = int(os.environ['SLURM_ARRAY_TASK_ID']) - 1\n",
    "except KeyError:\n",
    "    i_job = 0\n",
    "    prototype = True\n",
    "params, i_seed = micro_configs[i_job]\n",
    "i_config = i_job//n_seeds\n",
    "\n",
    "new_random_seed_per_condition = True\n",
    "if new_random_seed_per_condition:\n",
    "    np.random.seed(i_job + 120)\n",
    "else: #Match random seeds across conditions\n",
    "    np.random.seed(i_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99adf322",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Set empirical parameters --- ###\n",
    "\n",
    "#network properties size\n",
    "N = 10000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa426f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Set tasks\n",
    "R = 2\n",
    "gamma = 0.99\n",
    "alpha = 1\n",
    "N_tasks = int(alpha * N)\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "#g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "#D = D * g_correction\n",
    "D_bulk = 2\n",
    "D = np.ones(N_tasks) * D_bulk\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance_block_haar(R=R,\n",
    "                                                                                            gamma=gamma,\n",
    "                                                                                            report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393f4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- DIMENSIONALITY PC CARTOONS --- ###\n",
    "\n",
    "N_loops = 30\n",
    "T_sim = 4000\n",
    "\n",
    "## Spontaneous\n",
    "seed = i_seed\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance_block_haar(R=R,\n",
    "                                                                                            gamma=gamma,\n",
    "                                                                                            report_attempts=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05290a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N, seed=seed)\n",
    "x_cov, r_cov = estimate_cov_eigs(T_sim=T_sim, dt_save=1, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                                 T_save_delay=1000, N_batch=1, N_loops=N_loops,\n",
    "                                 return_raw_covs=True, runga_kutta=True)\n",
    "eigs_x, VT_x = np.linalg.eigh(x_cov)\n",
    "eigs_r, VT_r = np.linalg.eigh(r_cov)\n",
    "\n",
    "x1, r1 = sample_activity(T_sim=1200, dt_save=0.05, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=True, T_save_delay=200)\n",
    "PCs_x1 = x1.dot(VT_x[:,np.argsort(eigs_x)[::-1][:3]])\n",
    "PCs_r1 = r1.dot(VT_r[:,np.argsort(eigs_r)[::-1][:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85ff7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structured\n",
    "\n",
    "freq = 0.25\n",
    "Cs = np.transpose(sigma_mn_all, axes=(2,0,1))\n",
    "theta0 = np.arctan(freq)\n",
    "real_freq = gamma * np.cos(theta0)\n",
    "i_mode = np.argmin(np.abs(np.amax(np.linalg.eigvals(Cs).real, 1) - real_freq))\n",
    "D_changed = D.copy()\n",
    "#D_changed[i_mode] = 5\n",
    "D_changed[i_mode] = 4.15\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D_changed, N, seed=seed)\n",
    "x_cov, r_cov = estimate_cov_eigs(T_sim=T_sim, dt_save=1, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                                 T_save_delay=1000, N_batch=1, N_loops=N_loops, x0=None,\n",
    "                                 return_raw_covs=True, runga_kutta=True)\n",
    "eigs_x, VT_x = np.linalg.eigh(x_cov)\n",
    "eigs_r, VT_r = np.linalg.eigh(r_cov)\n",
    "\n",
    "x0 = torch.tensor(x1[-1]).to(torch.float).to(0)[None,:]\n",
    "x2, r2 = sample_activity(T_sim=1000, dt_save=0.05, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=True, T_save_delay=0, x0=x0)\n",
    "PCs_x2 = x2.dot(VT_x[:,np.argsort(eigs_x)[::-1][:3]])\n",
    "PCs_r2 = r2.dot(VT_r[:,np.argsort(eigs_r)[::-1][:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb806e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deterministic\n",
    "\n",
    "freq = 0.25\n",
    "Cs = np.transpose(sigma_mn_all, axes=(2,0,1))\n",
    "theta0 = np.arctan(freq)\n",
    "real_freq = gamma * np.cos(theta0)\n",
    "i_mode = np.argmin(np.abs(np.amax(np.linalg.eigvals(Cs).real, 1) - real_freq))\n",
    "D_changed = D.copy()\n",
    "\n",
    "D_changed[i_mode] = 5.3\n",
    "#D_changed[i_mode] = 10\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D_changed, N, seed=seed)\n",
    "x_cov, r_cov = estimate_cov_eigs(T_sim=T_sim, dt_save=1, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                                 T_save_delay=1000, N_batch=1, N_loops=N_loops, x0=None,\n",
    "                                 return_raw_covs=True, runga_kutta=True)\n",
    "eigs_x, VT_x = np.linalg.eigh(x_cov)\n",
    "eigs_r, VT_r = np.linalg.eigh(r_cov)\n",
    "\n",
    "x0 = torch.tensor(x2[-1]).to(torch.float).to(0)[None,:]\n",
    "x3, r3 = sample_activity(T_sim=1000, dt_save=0.05, dt=0.05, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=True, T_save_delay=0, x0=x0)\n",
    "\n",
    "PCs_x3 = x3.dot(VT_x[:,np.argsort(eigs_x)[::-1][:3]])\n",
    "PCs_r3 = r3.dot(VT_r[:,np.argsort(eigs_r)[::-1][:3]])\n",
    "#PCs_x3 = x3.dot(VT_x[:,:3])\n",
    "#PCs_r3 = r3.dot(VT_r[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf57ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D   # (import registers the 3D projection)\n",
    "# colors = ['C0', '#E89825']\n",
    "# #data = np.load('../packaged_results/dim_cartoon_traces.npz')\n",
    "# #x1, x2, x3 = data['x1'], data['x2'], data['x3']\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# axis_scale = 15\n",
    "\n",
    "# axis_scale = 600\n",
    "# ax.plot([0,axis_scale], [0,0], [0,0], color='k')\n",
    "# ax.plot([0,0], [0,-axis_scale], [0,0], color='k')\n",
    "# ax.plot([0,0], [0,0], [0,axis_scale], color='k')\n",
    "# ax.plot(PCs_x3[:,0], PCs_x3[:,1], PCs_x3[:,2], color=colors[0])\n",
    "# ax.plot(PCs_r3[:,0], PCs_r3[:,1], PCs_r3[:,2], color=colors[1])\n",
    "# #ax.plot(r3[:,0], r3[:,1], r3[:,2], color=colors[2])\n",
    "# ax.axis('off')\n",
    "# #fig.savefig('../figs/determ_dim_cartoon.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a651b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = np.array([PCs_x1, PCs_x2, PCs_x3, PCs_r1, PCs_r2, PCs_r3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SAVE RESULTS -- ###\n",
    "result = {'sim': sigma_mn_all, 'dim_emp': None,\n",
    "          'i_seed': i_seed, 'config': params,\n",
    "          'i_config': i_config, 'i_job': i_job}\n",
    "try:\n",
    "    result['processed_data'] = processed_data\n",
    "except NameError:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    save_dir = os.environ['SAVEDIR']\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_path = os.path.join(save_dir, 'result_{}'.format(i_job))\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60885180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Figure_6_dim_cartoon.ipynb to script\n",
      "[NbConvertApp] Writing 58440 bytes to Figure_6_dim_cartoon.py\n",
      "awk: cmd. line:1: /###Truncate/ <IPython.core.autocall.ZMQExitAutocall object at 0x2abfe2ba98d0> <built-in function print>\n",
      "awk: cmd. line:1:                       ^ syntax error\n",
      "awk: cmd. line:1: /###Truncate/ <IPython.core.autocall.ZMQExitAutocall object at 0x2abfe2ba98d0> <built-in function print>\n",
      "awk: cmd. line:1:                                                                                ^ syntax error\n"
     ]
    }
   ],
   "source": [
    "###Truncate file above\n",
    "file_name = 'Figure_6_dim_cartoon'\n",
    "job_name = 'dim_cartoon_trajectories_7'\n",
    "project_dir = '/home/om2382/low-rank-dims/'\n",
    "main_script_path = os.path.join(project_dir, 'cluster_main_scripts', job_name + '.py')\n",
    "get_ipython().run_cell_magic('javascript', '', 'IPython.notebook.save_notebook()')\n",
    "get_ipython().system('jupyter nbconvert --to script --no-prompt {}.ipynb'.format(file_name))\n",
    "get_ipython().system('awk \"/###Truncate/ {{exit}} {{print}}\" {}.py'.format(file_name))\n",
    "get_ipython().system('sed -i \"/###Truncate/Q\" {}.py'.format(file_name))\n",
    "get_ipython().system('mv {}.py {}'.format(file_name, main_script_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99850352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/home/om2382/low-rank-dims/results/Multi_Task_Elife/dim_cartoon_trajectories_7/result_*’: No such file or directory\n",
      "sending incremental file list\n",
      "mft-theory/\n",
      "mft-theory/.DS_Store\n",
      "mft-theory/.gitignore\n",
      "mft-theory/README.md\n",
      "mft-theory/__init__.py\n",
      "mft-theory/jupyter_notebook.py\n",
      "mft-theory/main.ipynb\n",
      "mft-theory/.idea/\n",
      "mft-theory/.idea/mft-theory.iml\n",
      "mft-theory/.idea/misc.xml\n",
      "mft-theory/.idea/modules.xml\n",
      "mft-theory/.idea/vanilla-rtrl.iml\n",
      "mft-theory/.idea/vcs.xml\n",
      "mft-theory/.idea/workspace.xml\n",
      "mft-theory/.idea/codeStyles/\n",
      "mft-theory/.idea/codeStyles/codeStyleConfig.xml\n",
      "mft-theory/.ipynb_checkpoints/\n",
      "mft-theory/.ipynb_checkpoints/main-checkpoint.ipynb\n",
      "mft-theory/LDR_dim/\n",
      "mft-theory/LDR_dim/__init__.py\n",
      "mft-theory/LDR_dim/condensed_tasks.py\n",
      "mft-theory/LDR_dim/extensive_tasks.py\n",
      "mft-theory/LDR_dim/solve_ldr.ipynb\n",
      "mft-theory/LDR_dim/spectral_methods.py\n",
      "mft-theory/LDR_dim/util.py\n",
      "mft-theory/LDR_dim/LDR-dim/\n",
      "mft-theory/LDR_dim/LDR-dim/__init__.py\n",
      "mft-theory/LDR_dim/LDR-dim/solve_ldr.ipynb\n",
      "mft-theory/LDR_dim/LDR-dim/util.py\n",
      "mft-theory/cluster/\n",
      "mft-theory/cluster/__init__.py\n",
      "mft-theory/cluster/close_jupyter_notebook.py\n",
      "mft-theory/cluster/process_results.py\n",
      "mft-theory/cluster/start_jupyter_notebook.py\n",
      "mft-theory/cluster/submit_jobs.py\n",
      "mft-theory/cluster/sync_cluster.py\n",
      "mft-theory/core/\n",
      "mft-theory/core/Estimate_Cov.py\n",
      "mft-theory/core/Estimate_Psi.py\n",
      "mft-theory/core/Estimate_Single_Unit_Prop.py\n",
      "mft-theory/core/Sample_Activity.py\n",
      "mft-theory/core/Simulation.py\n",
      "mft-theory/core/Time_Cts_RNN.py\n",
      "mft-theory/core/Torch_Sim.py\n",
      "mft-theory/core/Update_Step.py\n",
      "mft-theory/core/__init__.py\n",
      "mft-theory/empirics/\n",
      "mft-theory/empirics/__init__.py\n",
      "mft-theory/empirics/dimensionality.py\n",
      "mft-theory/functions/\n",
      "mft-theory/functions/Function.py\n",
      "mft-theory/functions/__init__.py\n",
      "mft-theory/functions/mean_squared_error.py\n",
      "mft-theory/functions/tanh.py\n",
      "mft-theory/ode_methods/\n",
      "mft-theory/ode_methods/Euler.py\n",
      "mft-theory/ode_methods/ODE_Method.py\n",
      "mft-theory/ode_methods/RK4.py\n",
      "mft-theory/ode_methods/__init__.py\n",
      "mft-theory/plotting/\n",
      "mft-theory/plotting/__init__.py\n",
      "mft-theory/plotting/misc.py\n",
      "mft-theory/theory/\n",
      "mft-theory/theory/__init__.py\n",
      "mft-theory/theory/basic_dmft.py\n",
      "mft-theory/theory/cavity_method.py\n",
      "mft-theory/theory/david_dmft.py\n",
      "mft-theory/theory/low_rank_dmft.py\n",
      "mft-theory/theory/theory_utils.py\n",
      "mft-theory/training/\n",
      "mft-theory/training/RNN_function.py\n",
      "mft-theory/training/Sample_GP.py\n",
      "mft-theory/training/__init__.py\n",
      "mft-theory/training/plotting.py\n",
      "mft-theory/utils/\n",
      "mft-theory/utils/__init__.py\n",
      "mft-theory/utils/mathematical_tools.py\n",
      "mft-theory/utils/programming_tools.py\n",
      "\n",
      "sent 517,441 bytes  received 1,309 bytes  1,037,500.00 bytes/sec\n",
      "total size is 512,564  speedup is 0.99\n",
      "sbatch  --array=1-10 -A lkumar -p lkumar /home/om2382/low-rank-dims/job_scripts/dim_cartoon_trajectories_7.s\n"
     ]
    }
   ],
   "source": [
    "###Submit job to cluster\n",
    "n_jobs = len(micro_configs)\n",
    "write_job_file(job_name, py_file_name='{}.py'.format(job_name), mem=64, n_hours=24, n_gpus=1,\n",
    "               results_subdir='Multi_Task_Elife')\n",
    "job_script_path = os.path.join(project_dir, 'job_scripts', job_name + '.s')\n",
    "submit_job(job_script_path, n_jobs, execute=False,\n",
    "           results_subdir='Multi_Task_Elife', lkumar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c350a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "           5473344    lkumar  jupyter   om2382  R   22:12:34      1 ax15\r\n"
     ]
    }
   ],
   "source": [
    "###Get job status\n",
    "get_ipython().system('squeue -u om2382')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc0e6e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'configs_array' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_cartoon_trajectories_7\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m job_script_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_scripts\u001b[39m\u001b[38;5;124m'\u001b[39m, job_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m theory_results \u001b[38;5;241m=\u001b[39m unpack_processed_data(job_script_path, results_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti_Task_Elife\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mft-theory/cluster/submit_jobs.py:190\u001b[0m, in \u001b[0;36munpack_processed_data\u001b[0;34m(job_file_path, project_name, results_subdir)\u001b[0m\n\u001b[1;32m    186\u001b[0m             configs_array[key]\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m][key])\n\u001b[1;32m    188\u001b[0m     max_seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(max_seed, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 190\u001b[0m configs_array[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_seed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(max_seed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    191\u001b[0m key_order\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_seed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m### --- Sort individual config dimensions --- ####\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'configs_array' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "project_dir = '/home/om2382/low-rank-dims/'\n",
    "job_name = 'dim_cartoon_trajectories_7'\n",
    "job_script_path = os.path.join(project_dir, 'job_scripts', job_name + '.s')\n",
    "theory_results = unpack_processed_data(job_script_path, results_subdir='Multi_Task_Elife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_results[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b58de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theory_results[1][1,5,:,0], theory_results[1][1,5,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3877643",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('packaged_results/dim_cartoon_PCs_6', 'wb') as f:\n",
    "    pickle.dump(theory_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh packaged_results/dim_cartoon_PCs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = '#B5B5B5'\n",
    "col2 = '#ED842C'\n",
    "col3 = '#EE3248'\n",
    "i_crit = 4\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,i_crit,0,0], color='k', linestyle='--')\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,i_crit,0,1], color='k', linestyle='dashdot')\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 np.zeros_like(theory_results[0]['freq']),\n",
    "                 theory_results[1][:,i_crit,0,0], color=col1)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,i_crit,0,0],\n",
    "                 theory_results[1][:,i_crit,0,1], color=col2)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,i_crit,0,1],\n",
    "                 25*np.ones_like(theory_results[0]['freq']), color=col3)\n",
    "#plt.legend(['$D^{(\\mu)}_{\\mathrm{crit},1}$', '$D^{(\\mu)}_{\\mathrm{crit},2}$', 'spontaneous',\n",
    "#            'structured chaos', 'deterministic'], loc='lower right')\n",
    "plt.ylim([0, 11])\n",
    "plt.xlim([0.1, 2])\n",
    "plt.xlabel('frequency of condensed pattern')\n",
    "plt.ylabel('$D^{(\\mu)}$')\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,0])\n",
    "#plt.ylim([5, 12])\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,1]/theory_results[1][:,0,0])\n",
    "#plt.annotate('deterministic', xy=[2, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = '#B5B5B5'\n",
    "col2 = '#ED842C'\n",
    "col3 = '#EE3248'\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,0,0], color='k', linestyle='--')\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,0,1], color='k', linestyle='dashdot')\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 np.zeros_like(theory_results[0]['freq']),\n",
    "                 theory_results[1][:,0,0], color=col1)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,0,0],\n",
    "                 theory_results[1][:,0,1], color=col2)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,0,1],\n",
    "                 25*np.ones_like(theory_results[0]['freq']), color=col3)\n",
    "#plt.legend(['$D^{(\\mu)}_{\\mathrm{crit},1}$', '$D^{(\\mu)}_{\\mathrm{crit},2}$', 'spontaneous',\n",
    "#            'structured chaos', 'deterministic'], loc='lower right')\n",
    "plt.ylim([0, 14])\n",
    "#plt.xlim([0.1, 2])\n",
    "plt.xlabel('frequency of condensed pattern')\n",
    "plt.ylabel('$D^{(\\mu)}$')\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,0])\n",
    "#plt.ylim([5, 12])\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,1]/theory_results[1][:,0,0])\n",
    "#plt.annotate('deterministic', xy=[2, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c72a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/om2382/low-rank-dims/'\n",
    "job_name = 'large_bifurfaction_frequencies_gamma_06'\n",
    "job_script_path = os.path.join(project_dir, 'job_scripts', job_name + '.s')\n",
    "theory_results = unpack_processed_data(job_script_path, results_subdir='Multi_Task_Elife')\n",
    "\n",
    "col1 = '#B5B5B5'\n",
    "col2 = '#ED842C'\n",
    "col3 = '#EE3248'\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,0,0], color='k', linestyle='--')\n",
    "plt.plot(theory_results[0]['freq'], theory_results[1][:,0,1], color='k', linestyle='dashdot')\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 np.zeros_like(theory_results[0]['freq']),\n",
    "                 theory_results[1][:,0,0], color=col1)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,0,0],\n",
    "                 theory_results[1][:,0,1], color=col2)\n",
    "plt.fill_between(theory_results[0]['freq'],\n",
    "                 theory_results[1][:,0,1],\n",
    "                 25*np.ones_like(theory_results[0]['freq']), color=col3)\n",
    "#plt.legend(['$D^{(\\mu)}_{\\mathrm{crit},1}$', '$D^{(\\mu)}_{\\mathrm{crit},2}$', 'spontaneous',\n",
    "#            'structured chaos', 'deterministic'], loc='lower right')\n",
    "plt.ylim([0, 15])\n",
    "plt.xlim([0, 3.5])\n",
    "plt.xlabel('frequency of condensed pattern')\n",
    "plt.ylabel('$D^{(\\mu)}$')\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,0])\n",
    "#plt.ylim([5, 12])\n",
    "#plt.plot(theory_results[0]['freq'], theory_results[1][:,0,1]/theory_results[1][:,0,0])\n",
    "#plt.annotate('deterministic', xy=[2, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e940dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/om2382/low-rank-dims/results/Multi_Task_Elife/x_dim_theory_check/result_21', 'rb') as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,0,0],\n",
    "             '.', alpha=1, color='C{}'.format(i))\n",
    "for i in range(2):\n",
    "    for i_seed in range(10):\n",
    "        ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,0],\n",
    "                 '.', alpha=1, color='C{}'.format(i))\n",
    "        ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,1],\n",
    "                 alpha=1, color='k')\n",
    "        ax[1].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,2],\n",
    "                 '.', alpha=1, color='C{}'.format(i))\n",
    "        ax[1].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,3],\n",
    "                 alpha=1, color='k')\n",
    "for i in range(2):\n",
    "    for i_ax in range(2):\n",
    "        ax[i_ax].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,:,2*i_ax].mean(-1),\n",
    "                 alpha=1, color='C{}'.format(i))\n",
    "        ax[i_ax].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,:,2*i_ax].mean(-1),\n",
    "                 alpha=1, color='C{}'.format(i))\n",
    "#plt.yscale('log', base=2)\n",
    "ax[0].set_xticks(theory_results[0]['D_crit_factor'][::2])\n",
    "ax[1].set_xticks(theory_results[0]['D_crit_factor'][::2])\n",
    "ax[0].set_xlabel('$D/D_\\mathrm{crit}$')\n",
    "ax[1].set_xlabel('$D/D_\\mathrm{crit}$')\n",
    "ax[0].set_ylabel('$PR_x$')\n",
    "ax[1].set_ylabel('$PR_\\phi$')\n",
    "ax[0].legend(['$N = 3000$', '$N = 6000$'])\n",
    "ax[0].set_yscale('log', base=2)\n",
    "ax[1].set_yscale('log', base=2)\n",
    "ax[0].axhline(y=2, linestyle='--', color=('0.7'))\n",
    "ax[1].axhline(y=2, linestyle='--', color=('0.7'))\n",
    "#ax[1].set_xscale('log', base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,0,0],\n",
    "             '.', alpha=1, color='C{}'.format(i))\n",
    "for i in range(2):\n",
    "    for i_seed in range(4):\n",
    "        ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,0],\n",
    "                 '.', alpha=1, color='C{}'.format(i))\n",
    "        ax[0].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,1],\n",
    "                 alpha=1, color='k')\n",
    "        ax[1].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,2],\n",
    "                 '.', alpha=1, color='C{}'.format(i))\n",
    "        ax[1].plot(theory_results[0]['D_crit_factor'],theory_results[1][i,:,i_seed,3],\n",
    "                 alpha=1, color='k')\n",
    "#plt.yscale('log', base=2)\n",
    "ax[0].set_xticks(theory_results[0]['D_crit_factor'][::2])\n",
    "ax[1].set_xticks(theory_results[0]['D_crit_factor'][::2])\n",
    "ax[0].set_xlabel('$D/D_\\mathrm{crit}$')\n",
    "ax[1].set_xlabel('$D/D_\\mathrm{crit}$')\n",
    "ax[0].set_ylabel('$PR_x$')\n",
    "ax[1].set_ylabel('$PR_\\phi$')\n",
    "ax[0].legend(['$N = 3000$', '$N = 6000$'])\n",
    "ax[0].set_yscale('log', base=2)\n",
    "ax[1].set_yscale('log', base=2)\n",
    "#ax[1].set_xscale('log', base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb826e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.plot(theory_results[0]['D_1'],theory_results[1][i,:,:,0].mean(-1),\n",
    "             '.', alpha=1, color='C{}'.format(i))\n",
    "plt.yscale('log', base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(3):\n",
    "    N = theory_results[0]['N'][i]\n",
    "    for i_seed in range(10):\n",
    "        plt.plot(theory_results[0]['D_1'], theory_results[1][i,:,i_seed,0]/N, '.', color='C{}'.format(i))\n",
    "plt.yscale('log', base=2)\n",
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(3):\n",
    "    N = theory_results[0]['N'][i]\n",
    "    for i_seed in range(10):\n",
    "        plt.plot(theory_results[0]['D_1'], theory_results[1][i,:,i_seed,0], '.', color='C{}'.format(i))\n",
    "plt.yscale('log', base=2)\n",
    "#plt.yscale('log', base=2)\n",
    "#plt.yticks([1, 2, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(3):\n",
    "    N = theory_results[0]['N'][i]\n",
    "    plt.plot(theory_results[0]['D_1'], theory_results[1][i,:,:,0].mean(1)/N, '.', color='C{}'.format(i))\n",
    "plt.yscale('log', base=2)\n",
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(3):\n",
    "    N = theory_results[0]['N'][i]\n",
    "    plt.plot(theory_results[0]['D_1'], theory_results[1][i,:,:,0].mean(1), '.', color='C{}'.format(i))\n",
    "plt.yscale('log', base=2)\n",
    "#plt.yscale('log', base=2)\n",
    "#plt.yticks([1, 2, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4d8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db57508",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_sym = 0\n",
    "i_C_sigma = 0\n",
    "i_PR_D = 2\n",
    "plt.figure(figsize=(2, 2))\n",
    "theory = theory_results[1][i_sym, i_C_sigma, i_PR_D,:,2,:].mean(0)\n",
    "sim = theory_results[1][i_sym, i_C_sigma, i_PR_D,:,3,:].mean(0)\n",
    "plt.plot(theory)\n",
    "plt.plot(sim)\n",
    "plt.xlim([0, 1000])\n",
    "ymax = np.amax(np.concatenate([theory, sim]))\n",
    "plt.ylim([0, ymax * 1.05])\n",
    "plt.figure(figsize=(2, 2))\n",
    "theory = theory_results[1][i_sym, i_C_sigma, i_PR_D,:,0,:].mean(0)\n",
    "sim = theory_results[1][i_sym, i_C_sigma, i_PR_D,:,1,:].mean(0)\n",
    "plt.plot(theory)\n",
    "plt.plot(sim)\n",
    "plt.xlim([0, 400])\n",
    "ymax = np.amax(np.concatenate([theory, sim]))\n",
    "ymin = np.amin(np.concatenate([theory, sim]))\n",
    "plt.ylim([ymin, ymax * 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678662df",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_results[1].shape\n",
    "fig, ax = plt.subplots(5, 3, figsize=(10, 10))\n",
    "for i_sym in range(5):\n",
    "    for i_g in range(3):\n",
    "        ax[i_sym,i_g].plot(theory_results[1][i_sym,i_g,0,0,:])\n",
    "        ax[i_sym,i_g].plot(theory_results[1][i_sym,i_g,0,1,:])\n",
    "        ax[i_sym,i_g].set_xlim([0, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65553b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_results[1].shape\n",
    "plt.plot(theory_results[1][0,0,0,2,:])\n",
    "plt.plot(theory_results[1][0,0,0,3,:])\n",
    "plt.xlim([0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network properties size\n",
    "#N = theory_results[0]['N'][i_N]\n",
    "\n",
    "def get_activity(i_g, i_sym):\n",
    "    #i_g = 0\n",
    "    #i_sym = 0\n",
    "    N = 5000\n",
    "    phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "    phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "    g = theory_results[0]['g'][i_g]\n",
    "    #g = 5\n",
    "    #lags window\n",
    "    T_window_emp = 1\n",
    "    dT_emp = 1\n",
    "    lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "    n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "    R = 2\n",
    "    #alpha = theory_results[0]['alpha'][i_alpha]\n",
    "    alpha = 0.5\n",
    "    N_tasks = int(alpha * N)\n",
    "    PR_D = 1\n",
    "    if PR_D < 1:\n",
    "        beta_D = invert_PR_by_newton(PR_D)\n",
    "        D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "    else:\n",
    "        D = np.ones(N_tasks)\n",
    "    g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "    D = D * g_correction\n",
    "\n",
    "    sym = theory_results[0]['sym'][i_sym]\n",
    "    sym = -1\n",
    "    sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "    total_attempts = 0\n",
    "    for i_task in range(N_tasks):\n",
    "        sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=0.6,\n",
    "                                                                                     sigma_off=0.6,\n",
    "                                                                                     symmetry_factor=sym,\n",
    "                                                                                     traceless=False, report_attempts=True)\n",
    "        total_attempts += n_attempts\n",
    "    W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "\n",
    "    ### --- Estimate S empirically --- ###\n",
    "\n",
    "    T_sim = 400\n",
    "    dt = 0.05\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch,\n",
    "                           runga_kutta=True, T_save_delay=200, noise_series=None)\n",
    "    Z = np.einsum('air, ti -> atr', all_loadings[:10, :, 2:4], r) * D[:10,None,None]\n",
    "    \n",
    "    return x, r, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(10, 10))\n",
    "for i_sym in range(5):\n",
    "    for i_g in range(3):\n",
    "        x, r, Z = get_activity(i_g, i_sym)\n",
    "        ax[i_sym, i_g].plot(x[:2000,0])\n",
    "        ax[i_sym, i_g].set_ylim([-15, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c684d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(10, 10))\n",
    "for i_sym in range(5):\n",
    "    for i_g in range(3):\n",
    "        x, r, Z = get_activity(i_g, i_sym)\n",
    "        ax[i_sym, i_g].plot(Z[0,:2000,0])\n",
    "        ax[i_sym, i_g].set_ylim([-15, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### --- Plot basic transients --- ###\n",
    "\n",
    "i_g = 0\n",
    "i_sym = 0\n",
    "N = 5000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 6\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "alpha = 0.5\n",
    "N_tasks = int(alpha * N)\n",
    "PR_D = 0.3\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "\n",
    "sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 300\n",
    "dt = 0.05\n",
    "x1, r1 = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=True, T_save_delay=200, noise_series=None)\n",
    "x0 = torch.tensor(x1[-1]).to(0)[None,:]\n",
    "m1 = torch.tensor(all_loadings[0,:,0]).to(0)\n",
    "n1 = torch.tensor(all_loadings[0,:,2]).to(0)\n",
    "x2, r2 = sample_activity(T_sim=5, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                       runga_kutta=True, T_save_delay=0, noise_series=None, input_current=300*m1)\n",
    "x0 = torch.tensor(x2[-1]).to(0)[None,:]\n",
    "#x0 = 300*n1[None,:]\n",
    "x3, r3 = sample_activity(T_sim=200, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                       runga_kutta=True, T_save_delay=0, noise_series=None, input_current=None)\n",
    "\n",
    "#x = np.concatenate([x1, x3], axis=0)\n",
    "#r = np.concatenate([r1, r3], axis=0)\n",
    "x = np.concatenate([x1, x2, x3], axis=0)\n",
    "r = np.concatenate([r1, r2, r3], axis=0)\n",
    "Z = np.einsum('air, ti -> atr', all_loadings[:6, :, 2:4], r) * D[:6,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6080f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('packaged_results/input_drive_transients.npz', Z=Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4974b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vec = np.arange(0, 305, dt)\n",
    "plt.plot(time_vec, Z[0,:,0])\n",
    "plt.plot(time_vec, Z[0,:,1])\n",
    "#plt.xlim([50, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plot basic transients --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "alpha = 0.5\n",
    "N_tasks = int(alpha * N)\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "sigma_mn_all[:,:,1] = np.array([[0.5, 0.3],[0.3, 0.5]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 100000\n",
    "dt = 0.1\n",
    "x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch,\n",
    "                       runga_kutta=False, T_save_delay=200, noise_series=None)\n",
    "Z = np.einsum('air, ti -> atr', all_loadings[:2, :, 2:4], r) * D[:2,None,None]\n",
    "#plt.plot(Z[0,:,0])\n",
    "#plt.plot(Z[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a48b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plot basic transients --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "alpha = 0.5\n",
    "N_tasks = int(alpha * N)\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "sigma_mn_all[:,:,1] = np.array([[0.5, 0.3],[0.3, 0.5]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 10000\n",
    "dt = 0.1\n",
    "N_runs = 50\n",
    "Zs = []\n",
    "for i_run in range(N_runs):\n",
    "    print(i_run)\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch,\n",
    "                           runga_kutta=False, T_save_delay=10, noise_series=None)\n",
    "    Z = np.einsum('air, ti -> atr', all_loadings[:2, :, 2:4], r) * D[:2,None,None]\n",
    "    Zs.append(Z)\n",
    "#plt.plot(Z[0,:,0])\n",
    "#plt.plot(Z[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d98ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 4000\n",
    "\n",
    "def compute_average_flow_field_cartesian_batches(all_batches, n_x_bins=20, n_y_bins=20,\n",
    "                                                   x_range=(-2.0, 2.0), y_range=(-2.0, 2.0)):\n",
    "    \"\"\"\n",
    "    Computes the average flow field over a Cartesian grid from a list of time series batches.\n",
    "    Each batch is treated independently so that the end of one batch and the start of the next\n",
    "    do not get connected.\n",
    "    \n",
    "    Parameters:\n",
    "      all_batches : list of np.ndarray\n",
    "          Each array is of shape (T, 2) representing a 2D trajectory for one batch.\n",
    "      n_x_bins : int\n",
    "          Number of bins in the x direction.\n",
    "      n_y_bins : int\n",
    "          Number of bins in the y direction.\n",
    "      x_range : tuple (x_min, x_max)\n",
    "          Range in the x direction.\n",
    "      y_range : tuple (y_min, y_max)\n",
    "          Range in the y direction.\n",
    "          \n",
    "    Returns:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      counts : np.ndarray, shape (n_x_bins, n_y_bins)\n",
    "          Number of velocity samples in each cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "    \"\"\"\n",
    "    # Prepare arrays for accumulation.\n",
    "    velocity_sum = np.zeros((n_x_bins, n_y_bins, 2))\n",
    "    counts = np.zeros((n_x_bins, n_y_bins))\n",
    "    \n",
    "    # Define the grid edges.\n",
    "    x_edges = np.linspace(x_range[0], x_range[1], n_x_bins + 1)\n",
    "    y_edges = np.linspace(y_range[0], y_range[1], n_y_bins + 1)\n",
    "    \n",
    "    # Process each batch separately.\n",
    "    for batch in all_batches:\n",
    "        # Skip batches that are too short.\n",
    "        if batch.shape[0] < 2:\n",
    "            continue\n",
    "        # Compute velocities within this batch.\n",
    "        velocities = np.diff(batch, axis=0)\n",
    "        # Use midpoints of consecutive points for binning.\n",
    "        positions = 0.5 * (batch[:-1] + batch[1:])\n",
    "        \n",
    "        for pos, vel in zip(positions, velocities):\n",
    "            x, y = pos\n",
    "            # Skip if outside region.\n",
    "            if (x < x_range[0]) or (x > x_range[1]) or (y < y_range[0]) or (y > y_range[1]):\n",
    "                continue\n",
    "            # Determine bin indices.\n",
    "            x_bin = int(np.floor((x - x_range[0]) / (x_range[1] - x_range[0]) * n_x_bins))\n",
    "            y_bin = int(np.floor((y - y_range[0]) / (y_range[1] - y_range[0]) * n_y_bins))\n",
    "            # Handle edge cases.\n",
    "            if x_bin == n_x_bins:\n",
    "                x_bin = n_x_bins - 1\n",
    "            if y_bin == n_y_bins:\n",
    "                y_bin = n_y_bins - 1\n",
    "            # Accumulate.\n",
    "            velocity_sum[x_bin, y_bin] += vel\n",
    "            counts[x_bin, y_bin] += 1\n",
    "    \n",
    "    # Compute the average velocities where counts > 0.\n",
    "    avg_flow = np.zeros_like(velocity_sum)\n",
    "    mask = counts > 0\n",
    "    avg_flow[mask] = velocity_sum[mask] / counts[mask, None]\n",
    "    \n",
    "    return avg_flow, counts, x_edges, y_edges\n",
    "\n",
    "def plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                     Z=None, limit_cycle=None, plot_only_first=True, fp=None, Z_long=None,\n",
    "                                     z_labels=None, sqrt_ticks=True, plot_arrows=False):\n",
    "    \"\"\"\n",
    "    Plots the average flow field on a Cartesian grid using streamplot.\n",
    "    \n",
    "    Parameters:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "      density : float\n",
    "          Controls the closeness of streamlines.\n",
    "      linewidth : float\n",
    "          Line width of the streamlines.\n",
    "      arrowsize : float\n",
    "          Size of the arrows.\n",
    "    \"\"\"\n",
    "    # Compute bin centers.\n",
    "    x_centers = 0.5 * (x_edges[:-1] + x_edges[1:])\n",
    "    y_centers = 0.5 * (y_edges[:-1] + y_edges[1:])\n",
    "    \n",
    "    # Extract averaged velocity components.\n",
    "    U = avg_flow[:, :, 0]\n",
    "    V = avg_flow[:, :, 1]\n",
    "    \n",
    "    # For streamplot, provide 1D coordinate arrays and transpose U and V.\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    if Z is not None:\n",
    "        for z in Z:\n",
    "            plt.plot(z[:,0], z[:,1], color='#AC85BC', alpha=1, linewidth=1, zorder=2)\n",
    "            if plot_arrows:\n",
    "                # Compute directional differences between successive points\n",
    "                dx = np.diff(z[:, 0])\n",
    "                dy = np.diff(z[:, 1])\n",
    "                speed = np.sqrt(dx**2 + dy**2)\n",
    "                dx = dx/speed\n",
    "                dy = dy/speed\n",
    "\n",
    "                # Choose arrow placement interval (adjust based on your data density)\n",
    "                arrow_interval = max(1, len(z) // 20)\n",
    "\n",
    "                # Plot arrows using quiver. We use z[:-1] since np.diff returns one fewer element.\n",
    "                plt.quiver(z[:-1:arrow_interval, 0], z[:-1:arrow_interval, 1],\n",
    "                           dx[::arrow_interval], dy[::arrow_interval],\n",
    "                           color='#AC85BC', scale_units='xy', angles='xy', scale=0.8,\n",
    "                            width=0.008,         # Arrow shaft thickness\n",
    "                            headwidth=15,         # Width of the arrow head\n",
    "                            headlength=15,        # Length of the arrow head\n",
    "                            headaxislength=15, zorder=3)\n",
    "\n",
    "            \n",
    "            if plot_only_first:\n",
    "                break\n",
    "    speed = np.log10(np.sqrt(U**2 + V**2) + 0.001)\n",
    "    plt.streamplot(x_centers, y_centers, U.T, V.T, density=density,\n",
    "                   color=speed, cmap='Greys', linewidth=linewidth, arrowsize=arrowsize)\n",
    "\n",
    "    if limit_cycle is not None:\n",
    "        plt.plot(limit_cycle[:,0], limit_cycle[:,1], color='k', linestyle='--', linewidth=0.8)\n",
    "    if fp is not None:\n",
    "        for fp_ in fp:\n",
    "            plt.plot([fp_[0]], [fp_[1]], 'x', color='k', markersize=3)\n",
    "    if Z_long is not None:\n",
    "        plt.plot(Z_long[:,0], Z_long[:,1], color='#AC85BC', linewidth=0.7)\n",
    "    if z_labels==1:\n",
    "        plt.xlabel('$z^{(1)}_1(t)$', fontsize=8)\n",
    "        plt.ylabel('$z^{(1)}_2(t)$', fontsize=8)\n",
    "    elif z_labels==2:\n",
    "        plt.xlabel('$z^{(2)}_1(t)$', fontsize=8)\n",
    "        plt.ylabel('$z^{(2)}_2(t)$', fontsize=8)\n",
    "    else:\n",
    "        plt.xlabel('$z_1(t)$', fontsize=8)\n",
    "        plt.ylabel('$z_2(t)$', fontsize=8)\n",
    "    #plt.title('Average Flow Field (Cartesian Grid, Batches)')\n",
    "    if sqrt_ticks:\n",
    "        plt.xticks([-np.sqrt(N), np.sqrt(N)], ['$-\\sqrt{N}$', '$\\sqrt{N}$'], fontsize=8)\n",
    "        plt.yticks([-np.sqrt(N), np.sqrt(N)], ['$-\\sqrt{N}$', '$\\sqrt{N}$'], fontsize=8)\n",
    "    else:\n",
    "        pass\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee622ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 15\n",
    "x_range = (-R, R)\n",
    "y_range = (-R, R)\n",
    "\n",
    "all_batches = [zs[1] for zs in Zs]\n",
    "\n",
    "# Compute the flow field for the distinct batches.\n",
    "avg_flow, counts, x_edges, y_edges = compute_average_flow_field_cartesian_batches(\n",
    "    all_batches, n_x_bins=20, n_y_bins=20, x_range=x_range, y_range=y_range)\n",
    "\n",
    "# Plot the flow field using a streamplot.\n",
    "fig = plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=0.3, arrowsize=0.4,\n",
    "                                       Z=None, plot_only_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6121ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches = Z[None,:0,:,:]\n",
    "\n",
    "R = 2\n",
    "x_range = (-R, R)\n",
    "y_range = (-R, R)\n",
    "\n",
    "# Compute the flow field for the distinct batches.\n",
    "avg_flow, counts, x_edges, y_edges = compute_average_flow_field_cartesian_batches(\n",
    "    all_batches, n_x_bins=20, n_y_bins=20, x_range=x_range, y_range=y_range)\n",
    "\n",
    "# Plot the flow field using a streamplot.\n",
    "plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                 Z=None, Z_long=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c257bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('packaged_results/MalphaN_limcyc_fp_2', Z=Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh packaged_results/MalphaN_limcyc_fp.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- M = 1 network --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "#alpha = 0.5\n",
    "#N_tasks = int(alpha * N)\n",
    "N_tasks = 1\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "D = D * 2 / D[0]\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "#sigma_mn_all[:,:,1] = np.array([[0.55, 0.4],[0.4, 0.55]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 20\n",
    "dt = 0.05\n",
    "N_runs = 1000\n",
    "#Z = np.zeros((1,int(T_sim/dt)*N_runs, 2))\n",
    "Zs = []\n",
    "for i_run in range(N_runs):\n",
    "    if i_run > 500:\n",
    "        ic_std = 50\n",
    "    else:\n",
    "        ic_std = 10\n",
    "#     if i_run == 0:\n",
    "#         T_sim = 20\n",
    "#     else:\n",
    "#         T_sim = 10\n",
    "    x0 = torch.tensor(all_loadings[0,:,2:4].dot(np.random.normal(0, ic_std, 2))).to(torch.float).to(0)[None,:]\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                           runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "    Z_ = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]\n",
    "    #Z[:,i_run * int(T_sim/dt): (i_run + 1)*int(T_sim/dt), :] = Z_\n",
    "    #if i_run > 0:\n",
    "        #from pdb import set_trace\n",
    "        #set_trace()\n",
    "    #    Z_ = np.concatenate([Z_, np.array([np.nan]*int(2*T_sim/dt)).reshape(-1, 2)[None,:,:]], axis=1)\n",
    "    Zs.append(Z_[0])\n",
    "#single long run for plotting line attractor\n",
    "Zs = np.array(Zs)\n",
    "x, r = sample_activity(T_sim=120, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=None,\n",
    "                       runga_kutta=False, T_save_delay=100, noise_series=None)\n",
    "Z_long = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('packaged_results/M=1_network_3', Zs=Zs, Z_long=Z_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8eb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- M = 2 network --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "#alpha = 0.5\n",
    "#N_tasks = int(alpha * N)\n",
    "N_tasks = 2\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "D = D * 2 / D[0]\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "sigma_mn_all[:,:,1] = np.array([[0.5, 0.3],[0.3, 0.5]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 40\n",
    "dt = 0.05\n",
    "N_runs = 1000\n",
    "#Z = np.zeros((1,int(T_sim/dt)*N_runs, 2))\n",
    "Zs = []\n",
    "for i_run in range(N_runs):\n",
    "    if i_run > 500:\n",
    "        ic_std = 50\n",
    "    else:\n",
    "        ic_std = 10\n",
    "#     if i_run == 0:\n",
    "#         T_sim = 20\n",
    "#     else:\n",
    "#         T_sim = 10\n",
    "    x0_1 = torch.tensor(all_loadings[0,:,2:4].dot(np.random.normal(0, ic_std, 2))).to(torch.float).to(0)[None,:]\n",
    "    x0_2 = torch.tensor(all_loadings[1,:,2:4].dot(np.random.normal(0, ic_std, 2))).to(torch.float).to(0)[None,:]\n",
    "    x0 = x0_1 + x0_2\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                           runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "    Z_ = np.einsum('air, ti -> atr', all_loadings[:2, :, 2:4], r) * D[:2,None,None]\n",
    "    #Z[:,i_run * int(T_sim/dt): (i_run + 1)*int(T_sim/dt), :] = Z_\n",
    "    #if i_run > 0:\n",
    "        #from pdb import set_trace\n",
    "        #set_trace()\n",
    "    #    Z_ = np.concatenate([Z_, np.array([np.nan]*int(2*T_sim/dt)).reshape(-1, 2)[None,:,:]], axis=1)\n",
    "    Zs.append(Z_)\n",
    "#single long run for plotting line attractor\n",
    "Zs = np.array(Zs)\n",
    "x, r = sample_activity(T_sim=120, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=None,\n",
    "                       runga_kutta=False, T_save_delay=100, noise_series=None)\n",
    "Z_long = np.einsum('air, ti -> atr', all_loadings[:2, :, 2:4], r) * D[:2,None,None]\n",
    "x, r = sample_activity(T_sim=120, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=None,\n",
    "                       runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "Z_long2 = np.einsum('air, ti -> atr', all_loadings[:2, :, 2:4], r) * D[:2,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('packaged_results/M=2_network_limcyc_fp', Zs=Zs, Z_long=Z_long, Z_long2=Z_long2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- M = 1 network --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "alpha = 0.5\n",
    "N_tasks = int(alpha * N)\n",
    "#N_tasks = 1\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "#D = D * 2 / D[0]\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "#sigma_mn_all[:,:,0] = np.array([[0.5, 0.3],[0.3, 0.5]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 20\n",
    "dt = 0.05\n",
    "N_runs = 1000\n",
    "#Z = np.zeros((1,int(T_sim/dt)*N_runs, 2))\n",
    "Zs = []\n",
    "for i_run in range(N_runs):\n",
    "    if i_run > 500:\n",
    "        ic_std = 50\n",
    "    else:\n",
    "        ic_std = 10\n",
    "#     if i_run == 0:\n",
    "#         T_sim = 20\n",
    "#     else:\n",
    "#         T_sim = 10\n",
    "    x0 = torch.tensor(all_loadings[0,:,2:4].dot(np.random.normal(0, ic_std, 2))).to(torch.float).to(0)[None,:]\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                           runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "    Z_ = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]\n",
    "    #Z[:,i_run * int(T_sim/dt): (i_run + 1)*int(T_sim/dt), :] = Z_\n",
    "    #if i_run > 0:\n",
    "        #from pdb import set_trace\n",
    "        #set_trace()\n",
    "    #    Z_ = np.concatenate([Z_, np.array([np.nan]*int(2*T_sim/dt)).reshape(-1, 2)[None,:,:]], axis=1)\n",
    "    Zs.append(Z_)\n",
    "#single long run for plotting line attractor\n",
    "Zs = np.array(Zs)\n",
    "x, r = sample_activity(T_sim=120, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=None,\n",
    "                       runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "Z_long = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3923d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('packaged_results/M=1_network_fp', Zs=Zs, Z_long=Z_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- M = \\alpha N network --- ###\n",
    "\n",
    "#i_g = 0\n",
    "#i_sym = 0\n",
    "N = 4000\n",
    "phi_torch = lambda x: torch.erf((np.sqrt(np.pi)/2)*x)\n",
    "phi_prime_torch = lambda x: torch.exp(-(np.pi/4)*x**2)\n",
    "#g = theory_results[0]['g'][i_g]\n",
    "g = 3\n",
    "#lags window\n",
    "T_window_emp = 1\n",
    "dT_emp = 1\n",
    "lags_emp = np.arange(0, T_window_emp, dT_emp)\n",
    "n_lags_emp = int(T_window_emp/dT_emp)\n",
    "\n",
    "R = 2\n",
    "#alpha = theory_results[0]['alpha'][i_alpha]\n",
    "#alpha = 0.5\n",
    "#N_tasks = int(alpha * N)\n",
    "N_tasks = 1\n",
    "PR_D = 1\n",
    "if PR_D < 1:\n",
    "    beta_D = invert_PR_by_newton(PR_D)\n",
    "    D = np.exp(-beta_D*np.arange(N_tasks)/N_tasks)\n",
    "else:\n",
    "    D = np.ones(N_tasks)\n",
    "g_correction = g / np.sqrt(np.sum(D**2)*R/N)\n",
    "D = D * g_correction\n",
    "D = D * 2 / D[0]\n",
    "\n",
    "#sym = theory_results[0]['sym'][i_sym]\n",
    "sym = 0\n",
    "sigma_mn_all = np.zeros((R, R, N_tasks))\n",
    "total_attempts = 0\n",
    "C_sigma = 0.5\n",
    "for i_task in range(N_tasks):\n",
    "    sigma_mn_all[:,:,i_task], n_attempts = generate_positive_definite_covariance(R=R, sigma_on=C_sigma,\n",
    "                                                                                 sigma_off=C_sigma,\n",
    "                                                                                 symmetry_factor=sym,\n",
    "                                                                                 traceless=False, report_attempts=True)\n",
    "    total_attempts += n_attempts\n",
    "print(total_attempts)\n",
    "sigma_mn_all[:,:,0] = np.array([[0.8, 0.4],[-0.4, 0.8]])\n",
    "#sigma_mn_all[:,:,1] = np.array([[0.55, 0.4],[0.4, 0.55]])\n",
    "D[0] = D[0] * 1\n",
    "W_, all_loadings = sample_W_optimized(sigma_mn_all, D, N)\n",
    "T_sim = 20\n",
    "dt = 0.05\n",
    "N_runs = 1000\n",
    "#Z = np.zeros((1,int(T_sim/dt)*N_runs, 2))\n",
    "Zs = []\n",
    "for i_run in range(N_runs):\n",
    "    if i_run > 500:\n",
    "        ic_std = 50\n",
    "    else:\n",
    "        ic_std = 10\n",
    "#     if i_run == 0:\n",
    "#         T_sim = 20\n",
    "#     else:\n",
    "#         T_sim = 10\n",
    "    x0 = torch.tensor(all_loadings[0,:,2:4].dot(np.random.normal(0, ic_std, 2))).to(torch.float).to(0)[None,:]\n",
    "    x, r = sample_activity(T_sim=T_sim, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=x0,\n",
    "                           runga_kutta=False, T_save_delay=0, noise_series=None)\n",
    "    Z_ = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]\n",
    "    #Z[:,i_run * int(T_sim/dt): (i_run + 1)*int(T_sim/dt), :] = Z_\n",
    "    #if i_run > 0:\n",
    "        #from pdb import set_trace\n",
    "        #set_trace()\n",
    "    #    Z_ = np.concatenate([Z_, np.array([np.nan]*int(2*T_sim/dt)).reshape(-1, 2)[None,:,:]], axis=1)\n",
    "    Zs.append(Z_[0])\n",
    "#single long run for plotting line attractor\n",
    "Zs = np.array(Zs)\n",
    "x, r = sample_activity(T_sim=120, dt_save=dt, dt=dt, W=W_, phi_torch=phi_torch, x0=None,\n",
    "                       runga_kutta=False, T_save_delay=100, noise_series=None)\n",
    "Z_long = np.einsum('air, ti -> atr', all_loadings[:1, :, 2:4], r) * D[:1,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ca69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches = Zs[:,0,:,:]\n",
    "\n",
    "R = 120\n",
    "x_range = (-R, R)\n",
    "y_range = (-R, R)\n",
    "\n",
    "# Compute the flow field for the distinct batches.\n",
    "avg_flow, counts, x_edges, y_edges = compute_average_flow_field_cartesian_batches(\n",
    "    all_batches, n_x_bins=20, n_y_bins=20, x_range=x_range, y_range=y_range)\n",
    "\n",
    "# Plot the flow field using a streamplot.\n",
    "plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                 Z=None, Z_long=Z_long[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70885cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_average_flow_field_cartesian_batches(all_batches, n_x_bins=20, n_y_bins=20,\n",
    "                                                   x_range=(-2.0, 2.0), y_range=(-2.0, 2.0)):\n",
    "    \"\"\"\n",
    "    Computes the average flow field over a Cartesian grid from a list of time series batches.\n",
    "    Each batch is treated independently so that the end of one batch and the start of the next\n",
    "    do not get connected.\n",
    "    \n",
    "    Parameters:\n",
    "      all_batches : list of np.ndarray\n",
    "          Each array is of shape (T, 2) representing a 2D trajectory for one batch.\n",
    "      n_x_bins : int\n",
    "          Number of bins in the x direction.\n",
    "      n_y_bins : int\n",
    "          Number of bins in the y direction.\n",
    "      x_range : tuple (x_min, x_max)\n",
    "          Range in the x direction.\n",
    "      y_range : tuple (y_min, y_max)\n",
    "          Range in the y direction.\n",
    "          \n",
    "    Returns:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      counts : np.ndarray, shape (n_x_bins, n_y_bins)\n",
    "          Number of velocity samples in each cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "    \"\"\"\n",
    "    # Prepare arrays for accumulation.\n",
    "    velocity_sum = np.zeros((n_x_bins, n_y_bins, 2))\n",
    "    counts = np.zeros((n_x_bins, n_y_bins))\n",
    "    \n",
    "    # Define the grid edges.\n",
    "    x_edges = np.linspace(x_range[0], x_range[1], n_x_bins + 1)\n",
    "    y_edges = np.linspace(y_range[0], y_range[1], n_y_bins + 1)\n",
    "    \n",
    "    # Process each batch separately.\n",
    "    for batch in all_batches:\n",
    "        # Skip batches that are too short.\n",
    "        if batch.shape[0] < 2:\n",
    "            continue\n",
    "        # Compute velocities within this batch.\n",
    "        velocities = np.diff(batch, axis=0)\n",
    "        # Use midpoints of consecutive points for binning.\n",
    "        positions = 0.5 * (batch[:-1] + batch[1:])\n",
    "        \n",
    "        for pos, vel in zip(positions, velocities):\n",
    "            x, y = pos\n",
    "            # Skip if outside region.\n",
    "            if (x < x_range[0]) or (x > x_range[1]) or (y < y_range[0]) or (y > y_range[1]):\n",
    "                continue\n",
    "            # Determine bin indices.\n",
    "            x_bin = int(np.floor((x - x_range[0]) / (x_range[1] - x_range[0]) * n_x_bins))\n",
    "            y_bin = int(np.floor((y - y_range[0]) / (y_range[1] - y_range[0]) * n_y_bins))\n",
    "            # Handle edge cases.\n",
    "            if x_bin == n_x_bins:\n",
    "                x_bin = n_x_bins - 1\n",
    "            if y_bin == n_y_bins:\n",
    "                y_bin = n_y_bins - 1\n",
    "            # Accumulate.\n",
    "            velocity_sum[x_bin, y_bin] += vel\n",
    "            counts[x_bin, y_bin] += 1\n",
    "    \n",
    "    # Compute the average velocities where counts > 0.\n",
    "    avg_flow = np.zeros_like(velocity_sum)\n",
    "    mask = counts > 0\n",
    "    avg_flow[mask] = velocity_sum[mask] / counts[mask, None]\n",
    "    \n",
    "    return avg_flow, counts, x_edges, y_edges\n",
    "\n",
    "def plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                     Z=None, Z_long=None):\n",
    "    \"\"\"\n",
    "    Plots the average flow field on a Cartesian grid using streamplot.\n",
    "    \n",
    "    Parameters:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "      density : float\n",
    "          Controls the closeness of streamlines.\n",
    "      linewidth : float\n",
    "          Line width of the streamlines.\n",
    "      arrowsize : float\n",
    "          Size of the arrows.\n",
    "    \"\"\"\n",
    "    # Compute bin centers.\n",
    "    x_centers = 0.5 * (x_edges[:-1] + x_edges[1:])\n",
    "    y_centers = 0.5 * (y_edges[:-1] + y_edges[1:])\n",
    "    \n",
    "    # Extract averaged velocity components.\n",
    "    U = avg_flow[:, :, 0]\n",
    "    V = avg_flow[:, :, 1]\n",
    "    \n",
    "    # For streamplot, provide 1D coordinate arrays and transpose U and V.\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if Z is not None:\n",
    "        for z in Z:\n",
    "            plt.plot(z[:,0], z[:,1], color='#AC85BC', alpha=0.3)\n",
    "            #plt.plot(z[:,0], z[:,1], color='#AC85BC', alpha=1, linewidth=1.5)\n",
    "            #break\n",
    "    if Z_long is not None:\n",
    "        plt.plot(Z_long[:,0], Z_long[:,1], color='#AC85BC', linewidth=1.5)\n",
    "    speed = np.log10(np.sqrt(U**2 + V**2) + 0.001)\n",
    "    plt.streamplot(x_centers, y_centers, U.T, V.T, density=density,\n",
    "                   color=speed, cmap='Greys', linewidth=linewidth, arrowsize=arrowsize)\n",
    "\n",
    "    plt.xlabel('$z_1(t)$', fontsize=20)\n",
    "    plt.ylabel('$z_2(t)$', fontsize=20)\n",
    "    #plt.title('Average Flow Field (Cartesian Grid, Batches)')\n",
    "    plt.xticks([-np.sqrt(N), np.sqrt(N)], ['$-\\sqrt{N}$', '$\\sqrt{N}$'], fontsize=20)\n",
    "    plt.yticks([-np.sqrt(N), np.sqrt(N)], ['$-\\sqrt{N}$', '$\\sqrt{N}$'], fontsize=20)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    all_batches = Zs[:,1,:,:]\n",
    "    \n",
    "    R = 120\n",
    "    x_range = (-R, R)\n",
    "    y_range = (-R, R)\n",
    "    \n",
    "    # Compute the flow field for the distinct batches.\n",
    "    avg_flow, counts, x_edges, y_edges = compute_average_flow_field_cartesian_batches(\n",
    "        all_batches, n_x_bins=20, n_y_bins=20, x_range=x_range, y_range=y_range)\n",
    "    \n",
    "    # Plot the flow field using a streamplot.\n",
    "    plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                     Z=Zs[:,1,:,:], Z_long=Z_long2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_average_flow_field_cartesian(all_series, n_x_bins=20, n_y_bins=20, x_range=(-2.0, 2.0), y_range=(-2.0, 2.0)):\n",
    "    \"\"\"\n",
    "    Computes the average flow field over a Cartesian grid from a list of time series.\n",
    "\n",
    "    Parameters:\n",
    "      all_series : list of np.ndarray\n",
    "          Each array is of shape (T, 2) representing a 2D trajectory.\n",
    "      n_x_bins : int\n",
    "          Number of bins in the x direction.\n",
    "      n_y_bins : int\n",
    "          Number of bins in the y direction.\n",
    "      x_range : tuple (x_min, x_max)\n",
    "          Range in the x direction.\n",
    "      y_range : tuple (y_min, y_max)\n",
    "          Range in the y direction.\n",
    "          \n",
    "    Returns:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      counts : np.ndarray, shape (n_x_bins, n_y_bins)\n",
    "          Number of velocity samples in each cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "    \"\"\"\n",
    "    # Create arrays to accumulate velocity sums and counts.\n",
    "    velocity_sum = np.zeros((n_x_bins, n_y_bins, 2))\n",
    "    counts = np.zeros((n_x_bins, n_y_bins))\n",
    "    \n",
    "    # Define grid edges.\n",
    "    x_edges = np.linspace(x_range[0], x_range[1], n_x_bins + 1)\n",
    "    y_edges = np.linspace(y_range[0], y_range[1], n_y_bins + 1)\n",
    "    \n",
    "    for series in all_series:\n",
    "        # Compute finite-difference velocities.\n",
    "        velocities = np.diff(series, axis=0)\n",
    "        # Compute midpoints between consecutive points.\n",
    "        positions = 0.5 * (series[:-1] + series[1:])\n",
    "        \n",
    "        for pos, vel in zip(positions, velocities):\n",
    "            x, y = pos\n",
    "            # Skip if the position is out of the defined range.\n",
    "            if (x < x_range[0]) or (x > x_range[1]) or (y < y_range[0]) or (y > y_range[1]):\n",
    "                continue\n",
    "            # Find the corresponding bin indices for x and y.\n",
    "            x_bin = int(np.floor((x - x_range[0]) / (x_range[1] - x_range[0]) * n_x_bins))\n",
    "            y_bin = int(np.floor((y - y_range[0]) / (y_range[1] - y_range[0]) * n_y_bins))\n",
    "            # Handle edge cases where position equals the upper bound.\n",
    "            if x_bin == n_x_bins:\n",
    "                x_bin = n_x_bins - 1\n",
    "            if y_bin == n_y_bins:\n",
    "                y_bin = n_y_bins - 1\n",
    "            # Accumulate velocity and count.\n",
    "            velocity_sum[x_bin, y_bin] += vel\n",
    "            counts[x_bin, y_bin] += 1\n",
    "    \n",
    "    # Compute average velocity where counts > 0.\n",
    "    avg_flow = np.zeros_like(velocity_sum)\n",
    "    mask = counts > 0\n",
    "    avg_flow[mask] = velocity_sum[mask] / counts[mask, None]\n",
    "    \n",
    "    return avg_flow, counts, x_edges, y_edges\n",
    "\n",
    "def plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1, arrowsize=1,\n",
    "                                     Z=None):\n",
    "    \"\"\"\n",
    "    Plots the average flow field on a Cartesian grid using streamplot.\n",
    "    \n",
    "    Parameters:\n",
    "      avg_flow : np.ndarray, shape (n_x_bins, n_y_bins, 2)\n",
    "          The average velocity vector in each grid cell.\n",
    "      x_edges, y_edges : np.ndarray\n",
    "          The bin edges for x and y.\n",
    "      density : float\n",
    "          Controls the closeness of streamlines.\n",
    "      linewidth : float\n",
    "          Line width of the streamlines.\n",
    "      arrowsize : float\n",
    "          Size of the arrows.\n",
    "    \"\"\"\n",
    "    # Compute bin centers from the edges.\n",
    "    x_centers = 0.5 * (x_edges[:-1] + x_edges[1:])\n",
    "    y_centers = 0.5 * (y_edges[:-1] + y_edges[1:])\n",
    "    \n",
    "    # Extract averaged velocity components.\n",
    "    U = avg_flow[:, :, 0]\n",
    "    V = avg_flow[:, :, 1]\n",
    "    \n",
    "    # Note: When providing 1D coordinate arrays, U and V need shape (len(y_centers), len(x_centers)).\n",
    "    # Our U and V are of shape (n_x_bins, n_y_bins), so we transpose them.\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    speed = np.log10(np.sqrt(U**2 + V**2) + 0.001)\n",
    "    plt.streamplot(x_centers, y_centers, U.T, V.T, density=density, color=speed,\n",
    "                   linewidth=linewidth, arrowsize=arrowsize, cmap='Greys')\n",
    "    if Z is not None:\n",
    "        plt.plot(Z[:,0], Z[:,1], color='#AC85BC')\n",
    "    plt.xlim([np.amin(x_edges), np.amax(x_edges)])\n",
    "    plt.ylim([np.amin(y_edges), np.amax(y_edges)])\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Average Flow Field (Cartesian Grid)')\n",
    "    #plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    all_series = [Z[0]]\n",
    "    # Define Cartesian region of interest.\n",
    "    R = 120\n",
    "    x_range = (-R, R)\n",
    "    y_range = (-R, R)\n",
    "    \n",
    "    # Compute the average flow field on the Cartesian grid.\n",
    "    avg_flow, counts, x_edges, y_edges = compute_average_flow_field_cartesian(\n",
    "        all_series, n_x_bins=20, n_y_bins=20, x_range=x_range, y_range=y_range)\n",
    "    \n",
    "    # Plot the estimated flow field using streamplot.\n",
    "    plot_flow_field_cartesian_stream(avg_flow, x_edges, y_edges, density=1.5, linewidth=1.5, arrowsize=1.5,\n",
    "                                     Z=Z[0,:2000])\n",
    "    #plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede5276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smn_all = theory_results[3]['0.8_8_0']\n",
    "S = torch.tensor(theory_results[1][i_sigma_off, i_seed, 0, :], dtype=torch.float32).to(0)\n",
    "C = torch.tensor(theory_results[1][i_sigma_off, i_seed, 2, :], dtype=torch.float32).to(0)\n",
    "N_t = C.shape[0]\n",
    "#T_extra = 1000\n",
    "dt = 0.05\n",
    "S_ = uni_rfft(S, dt)\n",
    "S_[1000:] = 0\n",
    "smoothed_S = uni_irfft(S_, dt)\n",
    "C_w = uni_rfft(C, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crr = np.array([[0.8, -0.4],[0.4, 0.8]])\n",
    "#Crr = Crr\n",
    "#Crr = Crr.T\n",
    "#T = len(C_phi)\n",
    "#t_indices= np.concatenate([np.arange(0, T//2), np.arange(-T//2, 0)])\n",
    "#sampfreq = 1/dT\n",
    "#w = 2*np.pi*sampfreq*t_indices/T\n",
    "S_omega = np.sqrt(2*np.pi)*S_.cpu().numpy()[:,None,None]\n",
    "M_inv = np.linalg.inv(np.eye(2)[None,:,:] - D[0]*Crr[None,:,:]*S_omega)\n",
    "M_invT = np.linalg.inv(np.eye(2)[None,:,:] - D[0]*Crr.T[None,:,:]*S_omega.conj())\n",
    "z_ccov = np.zeros_like(M_inv)\n",
    "for w in range(z_ccov.shape[0]):\n",
    "    z_ccov[w] = D[0]**2 * M_inv[w,:,:].dot(M_invT[w,:,:]) * C_w[w].cpu().numpy()\n",
    "z_ccov_w = torch.from_numpy(z_ccov).to(0)\n",
    "z_ccov_T = uni_irfft(z_ccov_w, 0.05, axis=0)\n",
    "#z_ccov_T = z_ccov_T.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ae8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_ccov_avg = theory_results[1][i_sigma_off, i_seed, :, :].T\n",
    "T = z_ccov_T.shape[0]\n",
    "\n",
    "i_task = 0\n",
    "acov_T_11 = torch.cat([z_ccov_T[:,0,0][T//2:], z_ccov_T[:,0,0][:T//2]]).cpu().numpy()\n",
    "acov_T_22 = torch.cat([z_ccov_T[:,1,1][T//2:], z_ccov_T[:,1,1][:T//2]]).cpu().numpy()\n",
    "ccov_T_12 = torch.cat([z_ccov_T[:,1,0][T//2:], z_ccov_T[:,1,0][:T//2]]).cpu().numpy()\n",
    "ccov_T_21 = torch.cat([z_ccov_T[:,0,1][T//2:], z_ccov_T[:,0,1][:T//2]]).cpu().numpy()\n",
    "acov_avg_11 = np.concatenate([z_ccov_avg[:,4+4*i_task][-T//2:], z_ccov_avg[:,4+4*i_task][:T//2]])\n",
    "acov_avg_22 = np.concatenate([z_ccov_avg[:,5+4*i_task][-T//2:], z_ccov_avg[:,5+4*i_task][:T//2]])\n",
    "ccov_avg_12 = np.concatenate([z_ccov_avg[:,6+4*i_task][-T//2:], z_ccov_avg[:,6+4*i_task][:T//2]])\n",
    "ccov_avg_21 = np.concatenate([z_ccov_avg[:,7+4*i_task][-T//2:], z_ccov_avg[:,7+4*i_task][:T//2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "acov_T_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "time_vec = np.arange(-len(acov_avg_11)*dt/2, len(acov_avg_11)*dt/2, dt)\n",
    "ax[0,0].plot(time_vec, acov_T_11, color='C0')\n",
    "ax[0,0].plot(time_vec, acov_avg_11, color='k', linestyle='--')\n",
    "ax[1,1].plot(time_vec, acov_T_22, color='C0')\n",
    "ax[1,1].plot(time_vec, acov_avg_22, color='k', linestyle='--')\n",
    "ax[0,1].plot(time_vec, ccov_T_12, color='C0')\n",
    "ax[0,1].plot(time_vec, ccov_avg_21, color='k', linestyle='--')\n",
    "ax[1,0].plot(time_vec, ccov_T_21, color='C0')\n",
    "ax[1,0].plot(time_vec, ccov_avg_12, color='k', linestyle='--')\n",
    "ax[0,0].set_title(r'$C^z_{11}(\\tau)$')\n",
    "ax[0,1].set_title(r'$C^z_{12}(\\tau)$')\n",
    "ax[1,0].set_title(r'$C^z_{21}(\\tau)$')\n",
    "ax[1,1].set_title(r'$C^z_{22}(\\tau)$')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].set_xlabel(r'$\\tau$')\n",
    "ax[0,0].legend(['sim', 'theory'])\n",
    "plt.tight_layout()\n",
    "fig.savefig('figs/cross_cov_fits.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-test-3",
   "language": "python",
   "name": "torch-test-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
